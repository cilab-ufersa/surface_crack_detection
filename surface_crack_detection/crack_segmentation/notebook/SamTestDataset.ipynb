{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O3Hxs3DCC4C"
      },
      "source": [
        "# 1. Preparando o ambiente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZAL7Vytj050"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "print(\"PyTorch version: \", torch.__version__)\n",
        "print(\"Torchvision version: \", torchvision.__version__)\n",
        "\n",
        "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
        "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "050FclvcqI2i"
      },
      "outputs": [],
      "source": [
        "%pip install -q roboflow supervision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iznDyk5pDNpG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
        "import cv2\n",
        "import supervision as sv\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HURXxConDcNq"
      },
      "source": [
        "# 2. Carregando o dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1wJHG_SDhKe"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset = os.listdir('dataset')\n",
        "images = []\n",
        "\n",
        "for paths in sorted(dataset):\n",
        "\n",
        "  image_bgr = cv2.imread(f'/content/dataset/{paths}')\n",
        "\n",
        "  image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  data = {'name': paths,\n",
        "        'bgr': image_bgr,\n",
        "        'rgb': image_rgb}\n",
        "\n",
        "  images.append(data)\n",
        "\n",
        "print(f\"O dataset contém {len(images)} imagens.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQwlf2ctEtwp"
      },
      "source": [
        "# 3. Configurando o Segment Anything Model (SAM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9j469bWEtX1",
        "outputId": "94aedb88-ca48-4099-e777-a1bc760b7ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dispositivo utilizado: cuda:0\n"
          ]
        }
      ],
      "source": [
        "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
        "model_type = \"vit_h\"\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
        "sam.to(device=device)\n",
        "\n",
        "mask_generator = SamAutomaticMaskGenerator(\n",
        "    model=sam,\n",
        "    points_per_side=32,\n",
        "    pred_iou_thresh=0.86,\n",
        "    stability_score_thresh=0.92,\n",
        "    crop_n_layers=1,\n",
        "    crop_n_points_downscale_factor=2,\n",
        "    min_mask_region_area=100)\n",
        "\n",
        "print(f\"Dispositivo utilizado: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KZui6SVGbCg"
      },
      "source": [
        "# 4. Gerando máscaras de cada imagem do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygPx0O6HGljv"
      },
      "outputs": [],
      "source": [
        "annotaded_images = []\n",
        "mask_annotator = sv.MaskAnnotator(color_lookup = sv.ColorLookup.INDEX)\n",
        "\n",
        "\n",
        "output = len(os.listdir('/content/output/'))\n",
        "print(f\"A pasta de Output possui {output} imagens\")\n",
        "\n",
        "for image in images:\n",
        "\n",
        "    sam_result = mask_generator.generate(image['rgb'])\n",
        "\n",
        "\n",
        "    detections = sv.Detections.from_sam(sam_result=sam_result)\n",
        "    annotaded_image = mask_annotator.annotate(scene=image['bgr'], detections=detections)\n",
        "\n",
        "    # salvando a imagem\n",
        "    cv2.imwrite(f'/content/output/{(image[\"name\"])}', annotaded_image)\n",
        "\n",
        "    annotaded_images.append(annotaded_image)\n",
        "\n",
        "print(f'Foram gerados {len(annotaded_images)} resultados')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
